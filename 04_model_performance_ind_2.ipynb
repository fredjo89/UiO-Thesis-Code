{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3fe91d9",
   "metadata": {},
   "source": [
    "# #1: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General \n",
    "import sys, numpy as np, pandas as pd, math, matplotlib.pyplot as plt, datetime, copy, os, re, random\n",
    "\n",
    "# Pytorch, pytorch Geometric\n",
    "import torch, torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Sklearn\n",
    "import sklearn\n",
    "\n",
    "sys.path.insert(1, '/home/ec2-user/SageMaker/repos/fredriks-thesis/python')\n",
    "import helper_functions, graph_preprocessing, nn_models, hetero_models, graphSage_models, div_models, logistic_models, han_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b498f",
   "metadata": {},
   "source": [
    "# #2: Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"/home/ec2-user/SageMaker/repos/fredriks-thesis/notebooks/09_model_performance_script/models/\"\n",
    "\n",
    "my_model_name = \"97_ind_logistic_02_features\"    \n",
    "\n",
    "# 01_ind_logistic / 02_ind_logistic_features / 03_ind_logistic2layer_features \n",
    "\n",
    "# 04_ind_graphSage1Layer / 05_ind_graphSage2Layer / 06_ind_graphSage3Layer / 07_ind_graphSage3Layer_features\n",
    "\n",
    "# 08_ind_NNConv1Layer / 09_ind_NNConv2Layer / 10_ind_NNConv3Layer / 11_ind_NNConv3Layer_features     \n",
    "\n",
    "# 12_ind_NNConv1Layer_concatmsg / 13_ind_NNConv2Layer_concatmsg / 14_ind_NNConv1Layer_concatmsg_features\n",
    "\n",
    "settings = {\n",
    "      'dataset': 1e4\n",
    "    , 'dataset_version': 'heterograph_externalnodes' \n",
    "    \n",
    "    , 'python_file': 'logistic_models'    # logistic_models / graphSage_models / nn_models / han_models\n",
    "    , 'model': 'logistic_02'        \n",
    "                                                # logistic_models:  logistic_01 / logistic_02 / \n",
    "                                                # graphSage_models: SAGEConv1Layer / SAGEConv2Layer / SAGEConv3Layer / SAGEConv4Layer \n",
    "                                                # nn_models\"        NNConv1Layer / NNConv2Layer / NNConv3Layer / NNConv4Layer \n",
    "                                                #                   / NNConv1Layer_concatmsg / NNConv2Layer_concatmsg / NNConv3Layer_concatmsg / NNConv4Layer_concatmsg\n",
    "    \n",
    "    , 'test_fraction': 0.3\n",
    "    , 'seed': 0\n",
    "    , 'train_who': 'ind'\n",
    "    , 'remove_num_txns': False\n",
    "    , 'learning_rate': 0.01\n",
    "    , 'weight_decay': 1e-6\n",
    "    , 'ca_num_batches': 0\n",
    "    , 'max_epochs': 20000\n",
    "    , 'n_batch_train': 1\n",
    "    , 'check_progress_frequency': 100\n",
    "    , 'lives': 5\n",
    "    , 'n_folds': 5\n",
    "    , 'delete_existing_models': False\n",
    "    # Node features\n",
    "    , 'degree_features'     : False\n",
    "    , 'centrality_features' : False\n",
    "    , 'deepwalk_features'   : False\n",
    "    , 'metapath_features_1' : False\n",
    "    , 'metapath_features_2' : False\n",
    "    , 'metapath_features_3' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model directory exists\n",
    "exists_str = '[ -d \"{0}\" ] && echo \"Directory/file {0} exists.\"'.format(model_file_path+my_model_name)\n",
    "exists = os.system(exists_str)\n",
    "\n",
    "# If it exists, and delete_existing = True, we delete existing repo\n",
    "if exists == 0 and settings['delete_existing_models']: os.system(\"rm -rf {}\".format(model_file_path+my_model_name));\n",
    "\n",
    "\n",
    "if exists != 0 or settings['delete_existing_models']: \n",
    "    # Create model directory\n",
    "    os.mkdir(model_file_path + my_model_name);\n",
    "\n",
    "    # Write train settings to text-file\n",
    "    with open(model_file_path + my_model_name + '/train_settings.txt', 'w') as f: f.write(str(settings).replace(', ', '\\n \\t,')) #f.write(str(settings).replace(', ', '\\n').replace('{','').replace('}','').replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a8ce7",
   "metadata": {},
   "source": [
    "# #3: Load Dataset and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f763814",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/ec2-user/SageMaker/s3/exploration-876679093433-ew1-initiative-pop-amlanalysis/data/fredriks-thesis/heterographs_01/'\n",
    "\n",
    "filename = settings['dataset_version'] + \"_{:.0f}.pt\".format(settings['dataset'])\n",
    "\n",
    "data = torch.load(filepath+filename)\n",
    "\n",
    "# Removing the attribute globalRiskScore\n",
    "data['ind'].x = torch.cat((data['ind'].x[:,0:4], data['ind'].x[:,5:data['ind'].x.shape[1]]), 1)\n",
    "data['org'].x = torch.cat((data['org'].x[:,0:3], data['org'].x[:,4:data['ind'].x.shape[1]]), 1)\n",
    "#data['ind'].attr_names.remove('globalRiskScore')\n",
    "#data['org'].attr_names.remove('globalRiskScore')\n",
    "\n",
    "torch.manual_seed(settings['seed']) # Setting torch random state seed\n",
    "\n",
    "# Create num_features variables\n",
    "data['ind'].num_features = data['ind'].x.shape[1]\n",
    "data['org'].num_features = data['org'].x.shape[1]\n",
    "data['ext'].num_features = data['ext'].x.shape[1]\n",
    "\n",
    "# Create train-and-test-sets\n",
    "data['ind'].test_mask = graph_preprocessing.create_test_mask(data['ind'].y, settings['test_fraction'])\n",
    "data['ind'].train_mask = ~data['ind'].test_mask\n",
    "data['org'].test_mask = graph_preprocessing.create_test_mask(data['org'].y, settings['test_fraction'])\n",
    "data['org'].train_mask = ~data['org'].test_mask\n",
    "\n",
    "# Create cv-mask\n",
    "data['ind'].cv_mask = graph_preprocessing.create_cv_mask(data['ind'].train_mask, settings['n_folds'])\n",
    "data['org'].cv_mask = graph_preprocessing.create_cv_mask(data['org'].train_mask, settings['n_folds'])\n",
    "\n",
    "# Add degree_features\n",
    "if settings['degree_features']:\n",
    "    my_filename = \"degfeatures_ind_{:.0f}.pt\".format(settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['ind'].x = torch.cat((data['ind'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "    my_filename = \"degfeatures_org_{:.0f}.pt\".format(settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['org'].x = torch.cat((data['org'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "    my_filename = \"degfeatures_ext_{:.0f}.pt\".format(settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['ext'].x = torch.cat((data['ext'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "    \n",
    "# Add centrality features\n",
    "if settings['centrality_features']:\n",
    "    my_filename = \"centralities_ind_{:.0f}.pt\".format(settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['ind'].x = torch.cat((data['ind'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "    my_filename = \"centralities_org_{:.0f}.pt\".format(settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['org'].x = torch.cat((data['org'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "# Add deepwalk features\n",
    "if settings['deepwalk_features']:\n",
    "    my_filename = \"deepwalk_features_ind_{:.0f}.pt\".format(settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['ind'].x = torch.cat((data['ind'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "    my_filename = \"deepwalk_features_org_{:.0f}.pt\".format(settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['org'].x = torch.cat((data['org'].x.detach(), my_import.detach()), dim = 1)\n",
    "\n",
    "# Add metapath features\n",
    "if settings['metapath_features_1']: \n",
    "    my_filename = \"metapath_features_ind_{}_{:.0f}.pt\".format(1,settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['ind'].x = torch.cat((data['ind'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "    my_filename = \"metapath_features_org_{}_{:.0f}.pt\".format(1,settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['org'].x = torch.cat((data['org'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "if settings['metapath_features_2']:\n",
    "    my_filename = \"metapath_features_ind_{}_{:.0f}.pt\".format(2,settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['ind'].x = torch.cat((data['ind'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "    my_filename = \"metapath_features_org_{}_{:.0f}.pt\".format(2,settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['org'].x = torch.cat((data['org'].x.detach(), my_import.detach()), dim = 1)\n",
    "\n",
    "if settings['metapath_features_3']: \n",
    "    my_filename = \"metapath_features_ind_{}_{:.0f}.pt\".format(3,settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['ind'].x = torch.cat((data['ind'].x.detach(), my_import.detach()), dim = 1)\n",
    "    \n",
    "    my_filename = \"metapath_features_org_{}_{:.0f}.pt\".format(3,settings['dataset'])\n",
    "    my_import = torch.load(filepath+my_filename)\n",
    "    data['org'].x = torch.cat((data['org'].x.detach(), my_import.detach()), dim = 1)\n",
    "\n",
    "# Reversing all edges \n",
    "data = graph_preprocessing.reverse_edges(data)\n",
    "# Applying log to node feature transaction amounts and edge feature transaction amounts: \n",
    "data = graph_preprocessing.apply_log_to_txns(data)\n",
    "# Normalizing node features\n",
    "data = graph_preprocessing.normalize_node_features(data)\n",
    "# Scaling edge_attributes to be in range [0.01,1]\n",
    "data = graph_preprocessing.scaling_edge_attr(data)\n",
    "\n",
    "# Removing the edge-feature num_txns so that the graph has only one edge feature (sum_txns)\n",
    "if settings['remove_num_txns']==True: data = graph_preprocessing.remove_num_txns(data)\n",
    "\n",
    "# Adding dummy-features for role-edges; ones for all edges\n",
    "data[('ind', 'role', 'org')].edge_attr = torch.ones([data[('ind', 'role', 'org')].edge_index.shape[1],1], dtype = torch.float32)\n",
    "data[('org', 'rev_role', 'ind')].edge_attr = torch.ones([data[('org', 'rev_role', 'ind')].edge_index.shape[1],1], dtype = torch.float32)\n",
    "\n",
    "# Define device and transfer data to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3cfac3",
   "metadata": {},
   "source": [
    "# #4: Define training-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, optimizer, loss_fun, batch, batch_size, train_who):\n",
    "    optimizer.zero_grad()\n",
    "    pred_ind_train, pred_org_train = model.forward(batch.x_dict, batch.edge_index_dict, batch.edge_attr_dict)\n",
    "    pred = pred_ind_train[:batch_size]\n",
    "    labels = batch['ind'].y[:batch_size]\n",
    "    loss = loss_fun(pred, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss), pred, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96649d0",
   "metadata": {},
   "source": [
    "# #5: Training FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_total = helper_functions.stopwatch()\n",
    "\n",
    "train_hist_list = []\n",
    "best_model_list = []\n",
    "\n",
    "for fold in range(1, settings['n_folds']+1):\n",
    "    print(\"!!!STARTING FOLD NUMBER: {} !!!\".format(fold))    \n",
    "    \n",
    "    ################################################################################################\n",
    "    #1: Create a copy of data for this fold, and create the correct train/test-masks\n",
    "    ################################################################################################\n",
    "    data_fold = copy.deepcopy(data)\n",
    "    data_fold['ind'].test_mask = (data_fold['ind'].cv_mask==fold)\n",
    "    data_fold['ind'].train_mask = (data_fold['ind'].cv_mask != 0) & (data_fold['ind'].cv_mask != fold)\n",
    "\n",
    "\n",
    "    ################################################################################################\n",
    "    # 2: Remove uneccecary parts of the data for training\n",
    "    ################################################################################################\n",
    "    n_layers = int(re.sub('\\D', '', settings['model']))\n",
    "    batch_size = math.ceil(data_fold['ind'].train_mask[data_fold['ind'].train_mask].shape[0]/(settings['ca_num_batches']+1))\n",
    "    kwargs = {'num_workers': 8, 'persistent_workers': False}\n",
    "    train_loader = torch_geometric.loader.NeighborLoader(\n",
    "        data = data_fold,\n",
    "        num_neighbors= [-1]*n_layers, # 1- means: For all nodes in the batch, we fetch all neighbors. 1 means: We create the subgraph by one iteration (we do not expand the graph beyond the neighbors of the nodes in the batch)\n",
    "        input_nodes= ('ind', data_fold['ind'].train_mask),\n",
    "        shuffle = True,\n",
    "        batch_size = batch_size,\n",
    "        **kwargs)\n",
    "\n",
    "    for batch in iter(train_loader): data_train = batch.to(device)\n",
    "    #data_train = copy.deepcopy(data_fold)\n",
    "    #data_train.to(device)\n",
    "    \n",
    "    ################################################################################################\n",
    "    #3: Create Objects for Model, Loss Function and Optimizer\n",
    "    ################################################################################################        \n",
    "    if settings['python_file']== 'han_models':\n",
    "        model = getattr(eval(settings['python_file'] ), settings['model'])(\n",
    "            num_features_ind = data['ind'].num_features\n",
    "            , num_features_org = data['org'].num_features\n",
    "            , num_features_ext = data['ext'].num_features\n",
    "            , num_features_txn_edge = data[('ind', 'txn', 'ind')].edge_attr.shape[1]\n",
    "            , metadata = data.metadata()\n",
    "        ).to(device);\n",
    "    else:\n",
    "        model = getattr(eval(settings['python_file'] ), settings['model'])(\n",
    "            num_features_ind = data['ind'].num_features\n",
    "            , num_features_org = data['org'].num_features\n",
    "            , num_features_ext = data['ext'].num_features\n",
    "            , num_features_txn_edge = data[('ind', 'txn', 'ind')].edge_attr.shape[1]\n",
    "        ).to(device);\n",
    "    \n",
    "    loss_fun = torch.nn.BCELoss() \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=settings['learning_rate'], weight_decay=settings['weight_decay']) \n",
    "    \n",
    "    \n",
    "    ################################################################################################\n",
    "    #4: Checks if we should create new fold for this model, or load an old one\n",
    "    ################################################################################################\n",
    "    if not settings['delete_existing_models'] and os.path.isfile(model_file_path + my_model_name + \"/model_fold_{}\".format(fold)):         \n",
    "        train_hist_list.append(pd.read_csv(model_file_path + my_model_name + \"/train_hist_fold_{}.csv\".format(fold), index_col= 0)); # Read train hist lost        \n",
    "        # Read model file\n",
    "        model.load_state_dict(torch.load(model_file_path + my_model_name + \"/model_fold_{}\".format(fold)))\n",
    "        model.eval()\n",
    "        model.cpu()\n",
    "        best_model_list.append(model)\n",
    "        continue\n",
    "    \n",
    "    ################################################################################################\n",
    "    #5: !Training!\n",
    "    ################################################################################################\n",
    "    start_time = helper_functions.stopwatch()\n",
    "\n",
    "    max_epochs = settings['max_epochs']\n",
    "    n_batch_train = settings['n_batch_train']\n",
    "    check_progress_frequency = settings['check_progress_frequency']\n",
    "    lives = settings['lives']\n",
    "    progress_idxs = list(range(0,max_epochs,check_progress_frequency))\n",
    "    progress_idxs.append(max_epochs)\n",
    "    train_hist = pd.DataFrame( columns = ['auc_ind_train','auc_ind_test', 'pr_auc_ind_train', 'pr_auc_ind_test', 'loss_ind_train', 'loss_ind_test'])\n",
    "\n",
    "    model.train() # Initialize training\n",
    "    for epoch in range(max_epochs):\n",
    "        model.to(device)\n",
    "        for i in range(n_batch_train): train_batch(model, optimizer, loss_fun, data_train, batch_size = data_train['ind'].batch_size, train_who = 'ind')       \n",
    "        \n",
    "        ################################################################################################\n",
    "        ## Tracking Progress ##\n",
    "        ################################################################################################\n",
    "        if epoch%check_progress_frequency == 0 or epoch==max_epochs-1:\n",
    "            # 1: Move data_train from GPU to CPU, 2: Move data_fold from CPU to GPU, 3: Predict on data_fold, 4: Move data_fold back to CPU, 5: Move data_train back to GPU\n",
    "            data_train = data_train.cpu()\n",
    "            data_fold = data_fold.to(device)\n",
    "            pred_ind, pred_org = model.forward(data_fold.x_dict, data_fold.edge_index_dict, data_fold.edge_attr_dict)\n",
    "            data_fold = data_fold.cpu()\n",
    "            data_train = data_train.to(device)\n",
    "            \n",
    "            pred_ind = pred_ind.cpu()\n",
    "            pred_org = pred_org.cpu()\n",
    "            \n",
    "            pred_ind = torch.tensor([x+(random.random()*1e-10) for x in pred_ind.detach().numpy()], dtype = torch.float32)\n",
    "            pred_org = torch.tensor([x+(random.random()*1e-10) for x in pred_org.detach().numpy()], dtype = torch.float32)\n",
    "            \n",
    "            train_hist.loc[epoch] = pd.Series({  \n",
    "                'auc_ind_train': sklearn.metrics.roc_auc_score(data_fold['ind'].y[data_fold['ind'].train_mask].detach().numpy(), pred_ind[data_fold['ind'].train_mask].detach().numpy())\n",
    "              , 'auc_ind_test': sklearn.metrics.roc_auc_score(data_fold['ind'].y[data_fold['ind'].test_mask].detach().numpy(), pred_ind[data_fold['ind'].test_mask].detach().numpy())\n",
    "              , 'pr_auc_ind_train': helper_functions.pr_auc_score(data_fold['ind'].y[data_fold['ind'].train_mask].detach().numpy(), pred_ind[data_fold['ind'].train_mask].detach().numpy())\n",
    "              , 'pr_auc_ind_test': helper_functions.pr_auc_score(data_fold['ind'].y[data_fold['ind'].test_mask].detach().numpy(), pred_ind[data_fold['ind'].test_mask].detach().numpy())\n",
    "              , 'loss_ind_train': loss_fun( pred_ind[data_fold['ind'].train_mask], data_fold['ind'].y[data_fold['ind'].train_mask]).item()\n",
    "              , 'loss_ind_test': loss_fun( pred_ind[data_fold['ind'].test_mask], data_fold['ind'].y[data_fold['ind'].test_mask]).item() \n",
    "             })\n",
    "            \n",
    "            pred_ind = None; pred_org = None # Deleting these frees up GPU memory (for some unknown reason)\n",
    "            \n",
    "            # Save the best model so far\n",
    "            if train_hist.pr_auc_ind_test.loc[epoch] >= max(train_hist.pr_auc_ind_test): best_model = copy.deepcopy(model)\n",
    "            # Writing progress \n",
    "            tms = divmod((datetime.datetime.now() - start_time).days * 86400 + (datetime.datetime.now() - start_time).seconds, 60)            \n",
    "            my_string = \"Epoch:{}, Current Time: {}, Time Elapsed: {} min {} sek\".format(epoch, datetime.datetime.now().strftime(\"%H:%M:%S\"), tms[0], tms[1])\n",
    "            my_string += \", auc_ind_train: {:.4f}, pr_auc_ind_train: {:.4f}, loss_ind_train: {:.4f} auc_ind_test {:.4f}, pr_auc_ind_test: {:.4f}, loss_ind_test: {:.4f}\".format(\n",
    "                              train_hist.loc[epoch]['auc_ind_train'], train_hist.loc[epoch]['pr_auc_ind_train'], train_hist.loc[epoch]['loss_ind_train']\n",
    "                            , train_hist.loc[epoch]['auc_ind_test'], train_hist.loc[epoch]['pr_auc_ind_test'], train_hist.loc[epoch]['loss_ind_test'])\n",
    "            # Early stopping\n",
    "            if epoch in range(max_epochs-1):\n",
    "                ind_decreasing = train_hist.auc_ind_test.loc[epoch] < max(train_hist.auc_ind_test) and train_hist.pr_auc_ind_test.loc[epoch] < max(train_hist.pr_auc_ind_test) and train_hist.loss_ind_test.loc[epoch] != min(train_hist.loss_ind_test)\n",
    "                if  epoch > 1 and (    train_hist.pr_auc_ind_test.loc[epoch] < train_hist.pr_auc_ind_test[epoch-check_progress_frequency]\n",
    "                                    or train_hist.loss_ind_train.loc[epoch] > train_hist.loss_ind_train[epoch-check_progress_frequency]): \n",
    "                        lives-=1; my_string+=\". Lost a life! Remaining lives: {}\".format(lives);\n",
    "                elif lives < settings['lives']:                                              lives+=1; my_string+=\". Gained a life! Remaining lives: {}\".format(lives);\n",
    "            print(my_string)\n",
    "            if lives==0 or epoch==max_epochs-1: \n",
    "                print('!Stopping! Performance decreasing!'); \n",
    "                train_hist_list.append(train_hist); \n",
    "                best_model_list.append(best_model); \n",
    "                torch.save(best_model.state_dict(), model_file_path + my_model_name + \"/model_fold_{}\".format(fold)) # Save best model to file\n",
    "                train_hist.to_csv(model_file_path + my_model_name + \"/train_hist_fold_{}.csv\".format(fold)) # Save train_hist\n",
    "                break;\n",
    "        ################################################################################################\n",
    "            \n",
    "    model = best_model\n",
    "    helper_functions.stopwatch(start_time)\n",
    "    ################################################################################################\n",
    "    \n",
    "helper_functions.stopwatch(start_time_total)\n",
    "helper_functions.sound_alert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd406aa",
   "metadata": {},
   "source": [
    "# #6: CV-Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b2114",
   "metadata": {},
   "source": [
    "### Plotting Training Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 1\n",
    "\n",
    "plt.figure(figsize = (30,8))\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "for fold in range(0,settings['n_folds']): ax.plot(train_hist_list[fold]['auc_ind_train'], label = 'Train - Fold '+ str(fold), linewidth = lw, color = 'blue')\n",
    "for fold in range(0,settings['n_folds']): ax.plot(train_hist_list[fold]['auc_ind_test'],  label = 'Val - Fold '  + str(fold), linewidth = lw, linestyle='dashed', color = 'green')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('ROC AUC')\n",
    "#ax.legend();\n",
    "\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "for fold in range(0,settings['n_folds']): ax.plot(train_hist_list[fold]['pr_auc_ind_train'], label = 'Train - Fold '+ str(fold), linewidth = lw, color = 'blue')\n",
    "for fold in range(0,settings['n_folds']): ax.plot(train_hist_list[fold]['pr_auc_ind_test'],  label = 'Val - Fold '  + str(fold), linewidth = lw, linestyle='dashed', color = 'green')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('PRROC AUC')\n",
    "#ax.legend();\n",
    "\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "for fold in range(0,settings['n_folds']): ax.plot(train_hist_list[fold]['loss_ind_train'], label = 'Train - Fold '+ str(fold), linewidth = lw, color = 'blue')\n",
    "for fold in range(0,settings['n_folds']): ax.plot(train_hist_list[fold]['loss_ind_test'],  label = 'Val - Fold '  + str(fold), linewidth = lw, linestyle='dashed', color = 'green')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Log-loss')\n",
    "ax.set_yscale('log');\n",
    "#ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261dd6b",
   "metadata": {},
   "source": [
    "### Plotting AUCs of CV-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auc = False\n",
    "if plot_auc: \n",
    "    plt.figure(figsize = (30,15))\n",
    "    title_fontsize = 20\n",
    "    label_fontsize = 15\n",
    "    legend_fontsize = 15\n",
    "    lw = 0.8\n",
    "    ms = 0\n",
    "\n",
    "\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
    "    from matplotlib import pyplot\n",
    "\n",
    "    for fold in range(1, settings['n_folds']+1): \n",
    "        ################################################################################################\n",
    "        #1: Create a copy of data for this fold, and create the correct train/test-masks\n",
    "        ################################################################################################\n",
    "        data_fold = copy.deepcopy(data)\n",
    "        data_fold = data_fold.to(device)\n",
    "        data_fold['ind'].test_mask = (data_fold['ind'].cv_mask==fold)\n",
    "        data_fold['ind'].train_mask = (data_fold['ind'].cv_mask != 0) & (data_fold['ind'].cv_mask != fold)\n",
    "        data_fold = data_fold.to(\"cpu\")\n",
    "        model = best_model_list[fold-1].to(\"cpu\")\n",
    "\n",
    "        ################################################################################################\n",
    "        #2: Get predictions and labels for train and test\n",
    "        ################################################################################################\n",
    "        pred_ind, pred_org = model.forward(data_fold.x_dict, data_fold.edge_index_dict, data_fold.edge_attr_dict)\n",
    "        pred = pred_ind.detach().numpy() \n",
    "        y = data_fold['ind'].y.detach().numpy() \n",
    "        pred_train = pred[data_fold['ind'].train_mask]\n",
    "        y_train = y[data_fold['ind'].train_mask]\n",
    "        pred_test = pred[data_fold['ind'].test_mask]\n",
    "        y_test = y[data_fold['ind'].test_mask]\n",
    "        \n",
    "        pred_test = np.array([x+(random.random()*1e-10) for x in pred_test])\n",
    "        pred_train = np.array([x+(random.random()*1e-10) for x in pred_train])\n",
    "\n",
    "        ################################################################################################\n",
    "        #3: PLOT ROC-CURVE\n",
    "        ################################################################################################\n",
    "        # Train\n",
    "        ax = plt.subplot(2, 2, 1)\n",
    "        fpr_train, tpr_train, _ = roc_curve(y_train, pred_train)\n",
    "        pyplot.plot(fpr_train, tpr_train, marker='.', markersize = ms, linewidth = lw, label='AUC:%.3f' % (roc_auc_score(y_train, pred_train)))\n",
    "        # Test\n",
    "        ax = plt.subplot(2, 2, 2)\n",
    "        fpr, tpr, _ = roc_curve(y_test, pred_test)\n",
    "        pyplot.plot(fpr, tpr, marker='.', markersize = ms, linewidth = lw, label='AUC:%.3f' % (roc_auc_score(y_test, pred_test)))\n",
    "\n",
    "        ################################################################################################\n",
    "        #4: PLOT PR-CURVE\n",
    "        ################################################################################################\n",
    "        # Train\n",
    "        ax = plt.subplot(2, 2, 3)\n",
    "        train_precision, train_recall, _  = precision_recall_curve(y_train, pred_train)\n",
    "        pyplot.plot(train_recall, train_precision, linewidth = lw, marker='.', markersize = ms, label='AUC:%.3f' % (sklearn.metrics.auc(train_recall, train_precision)))\n",
    "        # Test\n",
    "        ax = plt.subplot(2, 2, 4)\n",
    "        test_precision, test_recall, _  = precision_recall_curve(y_test, pred_test)\n",
    "        pyplot.plot(test_recall, test_precision, marker='.', markersize = ms, linewidth = lw, label='AUC:%.3f' % (sklearn.metrics.auc(test_recall, test_precision)))\n",
    "\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    pyplot.plot([0,1],[0,1], linestyle='--', color = 'b', linewidth = lw)\n",
    "    pyplot.xlabel('False Positive Rate', fontsize = label_fontsize)\n",
    "    pyplot.ylabel('True Positive Rate', fontsize = label_fontsize)\n",
    "    pyplot.title('ROC-CURVE TRAIN', fontsize = title_fontsize)\n",
    "    pyplot.legend(fontsize = legend_fontsize)\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "    pyplot.plot([0,1],[0,1], linestyle='--', color = 'b', linewidth = lw)\n",
    "    pyplot.xlabel('False Positive Rate', fontsize = label_fontsize)\n",
    "    pyplot.ylabel('True Positive Rate', fontsize = label_fontsize)\n",
    "    pyplot.title('ROC-CURVE TEST', fontsize = title_fontsize)\n",
    "    pyplot.legend(fontsize = legend_fontsize)\n",
    "\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "    pyplot.xlabel('False Positive Rate', fontsize = label_fontsize)\n",
    "    pyplot.ylabel('True Positive Rate', fontsize = label_fontsize)\n",
    "    pyplot.title('PR-CURVE TRAIN', fontsize = title_fontsize)\n",
    "    pyplot.legend(fontsize = legend_fontsize)\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "    pyplot.xlabel('False Positive Rate', fontsize = label_fontsize)\n",
    "    pyplot.ylabel('True Positive Rate', fontsize = label_fontsize)\n",
    "    pyplot.title('PR-CURVE TEST', fontsize = title_fontsize)\n",
    "    pyplot.legend(fontsize = legend_fontsize)\n",
    "\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc257f0",
   "metadata": {},
   "source": [
    "## BEST MODEL STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_stats = pd.DataFrame( columns = ['auc_ind_train','auc_ind_test', 'pr_auc_ind_train', 'pr_auc_ind_test', 'loss_ind_train', 'loss_ind_test'])\n",
    "\n",
    "for fold in range(0,settings['n_folds']):   \n",
    "    yolo = train_hist_list[fold].loc[train_hist_list[fold].pr_auc_ind_test == max (train_hist_list[fold].pr_auc_ind_test)]\n",
    "    best_model_stats = best_model_stats.append(yolo)\n",
    "    \n",
    "best_model_stats['n_iterations'] = best_model_stats.index\n",
    "best_model_stats.agg(['mean','min', 'max', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a737e43f",
   "metadata": {},
   "source": [
    "# #7: Apply models using the best model in each fold (We Don't use the test set to pick the model!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#6: Predict on the full dataset on each model from each fold, and let the mean value be the final prediction\n",
    "################################################################################################\n",
    "import gc\n",
    "pred_ind = torch.zeros(data['ind'].x.shape[0], dtype = torch.float32)\n",
    "pred_org = torch.zeros(data['org'].x.shape[0], dtype = torch.float32)\n",
    "data.cpu()\n",
    "for fold in range(0,settings['n_folds']):  \n",
    "    gc.collect()\n",
    "    best_model_list[0].cpu()\n",
    "    pred_ind_fold, pred_org_fold = best_model_list[0].forward(data.x_dict, data.edge_index_dict, data.edge_attr_dict)\n",
    "    \n",
    "    \n",
    "    pred_ind_fold = torch.tensor([x+(random.random()*1e-10) for x in pred_ind_fold.detach().numpy()], dtype = torch.float32)\n",
    "    pred_org_fold = torch.tensor([x+(random.random()*1e-10) for x in pred_org_fold.detach().numpy()], dtype = torch.float32)\n",
    "    \n",
    "    \n",
    "    pred_ind = pred_ind + pred_ind_fold.detach()\n",
    "    pred_org = pred_org + pred_org_fold.detach()\n",
    "    del pred_ind_fold, pred_org_fold\n",
    "    \n",
    "pred_ind = pred_ind/(settings['n_folds'])\n",
    "pred_org = pred_org/(settings['n_folds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c07004",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#6: Plotting AUCs of final results\n",
    "################################################################################################\n",
    "start_time = helper_functions.stopwatch()\n",
    "\n",
    "plt.figure(figsize = (30,15))\n",
    "plt.figure(figsize = (30,15))\n",
    "title_fontsize = 20\n",
    "label_fontsize = 15\n",
    "legend_fontsize = 15\n",
    "lw = 1.5\n",
    "ms = 0\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#1: Get data and model\n",
    "model = model.to(\"cpu\")\n",
    "data = data.to(\"cpu\")\n",
    "\n",
    "#2: Get predictions and labels for train and test\n",
    "#pred_ind, pred_ind = model.forward(data.x_dict, data.edge_index_dict, data.edge_attr_dict)\n",
    "pred = pred_ind.detach().numpy() \n",
    "y = data['ind'].y.detach().numpy() \n",
    "pred_train = pred[data['ind'].train_mask]\n",
    "y_train = y[data['ind'].train_mask]\n",
    "pred_test = pred[data['ind'].test_mask]\n",
    "y_test = y[data['ind'].test_mask]\n",
    "\n",
    "#3: PLOT ROC-CURVE\n",
    "# Train\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, pred_train)\n",
    "pyplot.plot(fpr_train, tpr_train, marker='.', markersize = ms, linewidth = lw, label='AUC:%.3f' % (roc_auc_score(y_train, pred_train)))\n",
    "# Test\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "fpr, tpr, _ = roc_curve(y_test, pred_test)\n",
    "pyplot.plot(fpr, tpr, marker='.', markersize = ms, linewidth = lw, label='AUC:%.3f' % (roc_auc_score(y_test, pred_test)))\n",
    "\n",
    "#4: PLOT PR-CURVE\n",
    "# Train\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "train_precision, train_recall, _  = precision_recall_curve(y_train, pred_train)\n",
    "pyplot.plot(train_recall, train_precision, marker='.', markersize = ms, linewidth = lw, label='AUC:%.3f' % (sklearn.metrics.auc(train_recall, train_precision)))\n",
    "# Test\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "test_precision, test_recall, _  = precision_recall_curve(y_test, pred_test)\n",
    "pyplot.plot(test_recall, test_precision, marker='.', markersize = ms, linewidth = lw, label='AUC:%.3f' % (sklearn.metrics.auc(test_recall, test_precision)))\n",
    "    \n",
    "ax = plt.subplot(2, 2, 1)\n",
    "pyplot.plot([0,1],[0,1], linestyle='--', color = 'b')\n",
    "pyplot.xlabel('False Positive Rate', fontsize = label_fontsize)\n",
    "pyplot.ylabel('True Positive Rate', fontsize = label_fontsize)\n",
    "pyplot.title('ROC-CURVE TRAIN', fontsize = title_fontsize)\n",
    "pyplot.legend(fontsize = legend_fontsize)\n",
    "\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "pyplot.plot([0,1],[0,1], linestyle='--', color = 'b')\n",
    "pyplot.xlabel('False Positive Rate', fontsize = label_fontsize)\n",
    "pyplot.ylabel('True Positive Rate', fontsize = label_fontsize)\n",
    "pyplot.title('ROC-CURVE TEST', fontsize = title_fontsize)\n",
    "pyplot.legend(fontsize = legend_fontsize)\n",
    "\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "pyplot.xlabel('Recall', fontsize = label_fontsize)\n",
    "pyplot.ylabel('Precision', fontsize = label_fontsize)\n",
    "pyplot.title('PR-CURVE TRAIN', fontsize = title_fontsize)\n",
    "pyplot.legend(fontsize = legend_fontsize)\n",
    "\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "pyplot.xlabel('Recall', fontsize = label_fontsize)\n",
    "pyplot.ylabel('Precision', fontsize = label_fontsize)\n",
    "pyplot.title('PR-CURVE TEST', fontsize = title_fontsize)\n",
    "pyplot.legend(fontsize = legend_fontsize)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# printing key numbers for final model\n",
    "# ?\n",
    "\n",
    "helper_functions.stopwatch(start_time)\n",
    "helper_functions.sound_alert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e99bb",
   "metadata": {},
   "source": [
    "# #8: Looking at top-scoring nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d0fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_frac = 0.001\n",
    "df = pd.DataFrame(\n",
    "          np.concatenate((pred_test, y_test)).reshape((2,pred_test.shape[0])).T\n",
    "        , columns = ['score','y']).sort_values(by = 'score', ascending = False)\n",
    "lift_test =helper_functions.compute_lift(df, top_frac)\n",
    "print(\"Test Set Organizations: Top score for {:.2%} ({} customers): Precision: {:.4f}, Recall: {:.4f}, lift: {:.2f}\".format(top_frac, math.ceil(df.shape[0]*top_frac), lift_test[0], df.shape[0]*top_frac*lift_test[0]/df.loc[df.y==1].shape[0], lift_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31416118",
   "metadata": {},
   "source": [
    "## Creating Precision-Recall-Lift Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1 = df.loc[df.y==1].shape[0]\n",
    "n_0 = df.loc[df.y==0].shape[0]\n",
    "\n",
    "recalls = [0.001, 0.01, 0.05, 0.1, 0.5]\n",
    "n_1_recalls = [math.ceil(x*n_1) for x in recalls]\n",
    "\n",
    "l = len(recalls)\n",
    "df = df.reset_index(drop = True)\n",
    "df_1 = df.loc[df.y==1]\n",
    "\n",
    "n_1_recalls_index = [int(df_1.iloc[[x-1]].index.values) for x in n_1_recalls]\n",
    "precs = []\n",
    "for i in range(l):\n",
    "    precs.append(n_1_recalls[i]/(n_1_recalls_index[i]+1))\n",
    "    \n",
    "df_pr_rec = pd.DataFrame(np.concatenate(([x+1 for x in n_1_recalls_index],n_1_recalls,recalls,precs, [x/(n_1/(n_0+n_1)) for x in precs])).reshape(5,l), index = [\"Predicting 1\", \"Actual 1\",\"Recall\", \"Precision\", \"Lift\"])\n",
    "\n",
    "df_pr_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr_rec = pd.DataFrame(np.concatenate(([x*100 for x in recalls],[x*100 for x in precs], [x/(n_1/(n_0+n_1)) for x in precs])).reshape(3,l), index = [\"Recall (%)\", \"Precision (%)\", \"Lift\"])\n",
    "pd.set_option('display.precision', 2)\n",
    "df_pr_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRAUC = sklearn.metrics.auc(test_recall, test_precision)\n",
    "ROCAUC = roc_auc_score(y_test, pred_test)\n",
    "\n",
    "print(\"PRAUC: {:.6f}\".format(PRAUC))\n",
    "print(\"ROCAUC: {:.6f}\".format(ROCAUC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_geometric_env",
   "language": "python",
   "name": "conda_pytorch_geometric_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
